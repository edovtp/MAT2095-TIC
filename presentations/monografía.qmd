---
title: "MAT2035 - Taller de Iniciación Científica"
author: "Eduardo Vásquez"
number-sections: true
highlight-style: pygments
format: 
  pdf:
    documentclass: article
    toc: true
    include-in-header: header.tex
    toc-title: "Tabla de Contenidos"
  html:
    toc: true
    code-fold: true
execute: 
  cache: true
bibliography: references.bib
---

\newpage

\section*{Prefacio}

El objetivo de este taller es implementar el algoritmo SIGN [@ni_scalable_2020], que permite aplicar modelos de Mezcla Proceso de Dirichlet (DPM) para bases de datos grandes.

Todo este material fue confeccionado durante mi Taller de Iniciación Científica junto al profesor Fernando Quintana, durante el segundo semestre del 2022. Todo el código y material se encuentra disponible en el siguiente [repositorio](https://github.com/edovtp/MAT2095-TIC) de Github.

\newpage
# Introducción

El material presentado a continuación se enmarca en el área de la Estadística Bayesiana No-Paramétrica, por lo que, en primer lugar, es necesario presentar una breve introducción de ambos conceptos.

## Paradigma Bayesiano

Es común que al presentarnos como estadísticos se nos pregunte acerca de qué es lo que hacemos en nuestro trabajo. Ante esta pregunta, comúnmente respondemos que nuestro objetivo principal es el de cuantificar la incertidumbre. Explicamos, además, que para lo anterior nos apoyamos sobre la teoría de probabilidades, tomándola como herramienta principal para modelar aquellas incertezas de interés.

Pero, como estadísticos podemos ir un paso atrás, y preguntarnos acerca de a qué nos referimos exactamente con incertidumbre. Esta pregunta es la que nos lleva a las bases mismas de la estadística, así como a entender cómo surgieron dos visiones diferentes entre sí: la *Estadística Frecuentista* (también denominada clásica) y la *Estadística Bayesiana*.

En particular, Tony O'Hagan distingue dos tipos de incertidumbre [@ohagan_dicing_2004]. Una de ellas la podemos denominar *incerteza ontólogica* (o aleatoria), mientras que la otra toma el nombre de *incerteza epistemológica*. Es importante recordar que la ontología es el estudio del *ser*, mientras que la epistemología es el estudio del *saber*.

La incerteza ontológica trata acerca de una incerteza que está sujeta a una variabilidad aleatoria innata, que no podemos predecir bajo ninguna cantidad de información. Dentro de los ejemplos de incerteza ontológica se encuentran varios de los ejemplos introductorios a la estadística, como el lanzamiento de un dado o ganar la lotería.

Por otro lado, la incerteza epistemológica, tal como lo dice el nombre, es una incerteza acerca de lo que sabemos, como puede ser el...

Probabilidades subjetivas...

Como en estadística Bayesiana también consideramos medir mediante probabilidades los parámetros de nuestros modelos, debemos definir entonces un modelo conjunto de cantidades observables y no observables. Esto es,

$$
p(\mathbf{y}, \theta) = p(\mathbf{y}|\theta)\pi(\theta)
$$

Luego, a la luz de nueva información, se actualiza nuestra creencia a priori, mediante el teorema de Bayes, para obtener entonces la distribución a posteriori.

\begin{equation}\label{eq:1}
\begin{aligned}
\pi(\theta|\mathbf{y}) &= \frac{f(\mathbf{y}|\theta)\pi(\theta)}{\int_{\Theta}f(\mathbf{y}|\theta)\pi(\theta)d\theta} \\
&\propto f(\mathbf{y}|\theta)\pi(\theta)
\end{aligned}
\end{equation}

\begin{ejemplo}[Modelo Normal-Normal]
\end{ejemplo}

En el ejemplo anterior obtuvimos un resultado bastante conveniente. Al considerar una función de verosimilitud Normal, así como una priori Normal para $\theta$, obtuvimos que a posteriori la distribución sigue siendo una distribución Normal, con la actualización de los parámetros dada en (poner ecuación). Este tipo de modelos se denominan **conjugados**...

Ahora, nada nos debe restringir a ocupar modelos conjugados solo para poder trabajarlos de forma más fácil con resultados analíticos. En particular, vemos que, en un principio, tanto para la verosimilitud como para la priori podemos ocupar cualquier distribución de probabilidad. 

Uno de los cuellos de botella más importantes de la estadística bayesiana, que provocó el poco uso de esta...

* Métodos computacionales
  * Rejection Sampling
  * Importance Sampling
  * MCMC: Gibbs sampler, Slice sampling
  * MCMC: Metropolis y Metropolis-Hastings
  * MCMC: Hamiltonian Monte Carlo and No-U-Turn Sampler
  * MCMC: Sequential Monte Carlo

* Lenguajes probabilísticos
  * Stan
  * Turing
  * PyMC3

## Estadística No-Paramétrica

Normalmente, en estadística asumimos

$$
y_1,..., y_n | G \overset{i.i.d.}{\sim} G
$$

Suponemos que la densidad de $G$, $g$, pertenece a 

$$
\mathcal{G} = \{g_\theta\colon \theta \in \Theta \subset \mathbb{R}^p\}
$$

* Ejemplo

* Figura

::: {#fig-np layout-ncol=2}
![](figuras/NP%20-%20Example%201.jpg)

![](figuras/NP%20-%20Example%202.jpg)

Necesidad de métodos flexibles
:::


* Nos gustaría ir un poco más allá: estimación de densidades (figura) y regresión

\newpage
# Procesos de Dirichlet

Considerando lo anterior, debemos entonces definir medidas de probabilidad sobre medidas de probabilidad. Una de estas opciones es la del proceso de Dirichlet [@ferguson_bayesian_1973], que definimos a continuación.

```{=tex}
% Definición Proceso de Dirichlet
\begin{definicion}[(Ferguson, 1973)]
  Sea $\alpha>0$ y $G_0$ una medida de probabilidad definida sobre $S$. Un \textbf{Proceso de Dirichlet (DP)} de parámetros $(\alpha, G_0)$, denotado por $\text{DP}(\alpha, G_0)$, es una medida de probabilidad aleatoria $G$ definida en $S$ que asigna probabilidad $G(B)$ a todo conjunto medible $B$ tal que, para toda partición medible finita $\{B_1, ..., B_k\}$ de $S$, la distribución conjunta del vector $(G(B_1), ..., G(B_k))$ es Dirichlet con parámetros

$$
(\alpha G_0(B_1), ..., \alpha G_0(B_k))
$$


Los parámetros $G_0$ y $\alpha$ se denominan la medida de centralización y la precisión, respectivamente. También se suele denominar $\alpha G_0$ como la medida base.
\end{definicion}
```

Ferguson muestra que $G$ existe para todo $G_0$. Además, señala algunas de las propiedades estadísticas de los DP, tales como:

```{=tex}
\begin{propiedad}[(Propiedades Proceso de Dirichlet)]
  Sea $G \sim \text{DP}(\alpha, G_0$), $B, B_1$ y $B_2$ conjuntos medibles, con $B_1 \cap B_2 = \emptyset$. Luego,
  \begin{itemize}
    \item El soporte de $G$ coincide con el de $G_0$. Esto es,
    \begin{equation*}
      G_0(B) = 0 \implies P(G(B) = 0) = 1
    \end{equation*}
    y
    \begin{equation*}
      \quad G_0(B) > 0 \implies P(G(B) > 0) > 1 
    \end{equation*}
    \item $\text{E}(G(B)) = G_0(B)$
    \item $\text{Var}(G(B)) = \frac{G_0(B)(1 - G_0(B)}{1 + \alpha}$
    \item $\text{Cov}(G(B_1), G(B_2)) = \frac{-G_0(B_1)G_0(B_2)}{1 + \alpha}$
  \end{itemize}
\end{propiedad}
```

Las propiedades anteriores nos muestran la razón por la que $G_0$ se denomina la medida de centralización, así como el por qué $\alpha$ se denomina el parámetro de precisión. La covarianza muestra que la covarianza entre dos conjuntos cualesquiera es siempre negativa (acá hay extensiones, mencionar que están fuera del alcance de este trabajo)

```{=tex}
\begin{nota}
  Algunos se preguntarán, como yo lo hice la primera vez que aprendí sobre esto, el por qué se denomina un \textbf{proceso}. La razón es bastante sencilla, y es que el DP es un proceso estocástico que, en vez de estar indexado por índices comunes como el tiempo o coordenadas geográficas, está indexado por todos los conjuntos medibles, esto es, para cada conjunto medible $B$ tenemos la variable aleatoria $G(B)$.
\end{nota}
```

Una propiedad muy importante que muestra Ferguson, que será central en el transcurso de esta monografía, es que $G$ es casi-seguramente discreta. Este resultado nos dice que $G$ se puede escribir como una suma ponderada de masas puntuales, también denominados átomos, esto es,

$$
G(\cdot) = \sum_{h=1}^\infty w_h \delta_{m_h}(\cdot)
$$

donde $\sum_{h=1}^\infty w_h = 1$ y $\delta_{x}(\cdot)$ denota la medida de Dirac en $x$. En la Figura 2 se presenta gráficamente un Proceso de Dirichlet. A la izquierda se ilustran los átomos con puntos morados, donde los largos indican la masa que aporta cada uno. A la derecha se muestra cómo se calcularía la probabilidad para un cierto conjunto medible $B$, que es simplemente tomar la suma de las masas de los átomos que se encuentran dentro de este conjunto.

::: {#fig-dp layout-ncol=2}
![](figuras/DP%20-%20Definition.jpg)

![](figuras/DP%20-%20Definition%202.jpg)

Naturaleza discreta del Proceso de Dirichlet
:::

Por último, Ferguson tambien demuestra que un DP es conjugada para una muestra i.i.d. de esta distribución, donde se considera un promedio ponderado entre la medida de centralización $G_0$ y la función de distribución empírica de los datos.

```{=tex}
% Posteriori Proceso de Dirichlet
\begin{proposicion}[(Ferguson, 1973)]
  Sea $y_1, ..., y_n | G \overset{i.i.d}{\sim} G$ y $G \sim \text{DP}(\alpha, G_0)$. Luego,
  \begin{equation*}
    G | y_1, ..., y_n \sim \text{DP}\left(\alpha + n, \frac{\alpha G_0 + n \hat{f}_n}{\alpha + n}\right)
  \end{equation*}
  donde $\hat{f}_n$ es la distribución empírica obtenida a partir de los datos, i.e.
  \begin{equation*}
    \hat{f}_n(\cdot) = \frac{1}{n}\sum_{i=1}^n \delta_{y_i}(\cdot)
  \end{equation*}
\end{proposicion}
```

Ahora, todo lo anterior aún no nos dice mucho acerca de como trabajar con esta distribución, ya que de momento solo sabemos que existen tales procesos, así como algunas propiedades. En la práctica, se ha trabajado principalmente de dos formas. La primera es marginalizando la medida de probabilidad aleatoria $G$, esto es, trabajar directamente con

$$
p(y_1, ..., y_n) = \int p(y_1, ..., y_n|G) d\pi(G)
$$

La otra forma es considerar la construcción de un DP mediante una representación basada en cortar una varilla de largo unitario de manera sucesiva e indefinida, denominada *Stick-Breaking*.

## Construcción con Urnas de Pólya

Una de las formas de poder trabajar con un Proceso de Dirichlet es, irónicamente, no trabajar con él. En probabilidades esto lo logramos marginalizando con respecto a la medida que no es de interés.

Considerando una muestra aleatoria $y_1, ..., y_n|G \sim G$, Blackwell y MacQueen  [@blackwell_ferguson_1973] formulan una representación de la densidad marginal $p(y_1, ..., y_n)$ mediante una representación por Urnas de Pólya. En particular, se tiene que

$$
p(y_1, ..., y_n) = p(y_1)\prod_{i=2}^n p(y_i|y_1, ..., y_{i-1})
$$

y lo que muestran es que

$$
p(y_i|y_1, ..., y_{i-1}) = \frac{1}{M + i - 1}\sum_{h=1}^{i-1}\delta_{y_h}(y_i) + \frac{M}{M + i - 1}G_0(y_i)
$$

Hay dos cosas bastante importantes:

* Dada la intercambiabilidad, las condicionales completas toman la misma forma
* La predictiva toma la misma forma para $i = n + 1$
* Lo anterior se puede simplificar considerando solo los valores iguales

```{=tex}
\begin{ejemplo}[Urnas de Pólya]
  Para ilustrar, consideramos el ejemplo de obtener datos de un Proceso de Dirichlet con medida de centralización Gamma(6, 4) y precisión $\alpha = 1, 10, 50, 100, 1000, 10000$.
\end{ejemplo}
```


```{julia}
#| label: fig-crp-gamma
#| echo: false
#| fig-cap: Simulación de datos provenientes de un Proceso de Dirichlet con medida de centralización Gamma(6, 4) (en azul)
#| fig-subcap:
#|   - $\alpha$ = 1
#|   - $\alpha$ = 10
#|   - $\alpha$ = 50
#|   - $\alpha$ = 100
#|   - $\alpha$ = 1000
#|   - $\alpha$ = 10000
#| layout-ncol: 3
#| layout-nrow: 2

include("../src/00_extras.jl")
include("code/c2_f.jl")

Random.seed!(219);
G0 = Distributions.Gamma(6, 1/4);
display(tic_rdp_marginal_example(500, 1, G0))
display(tic_rdp_marginal_example(500, 10, G0))
display(tic_rdp_marginal_example(500, 50, G0))
display(tic_rdp_marginal_example(500, 100, G0))
display(tic_rdp_marginal_example(500, 1000, G0))
display(tic_rdp_marginal_example(500, 10000, G0))
```

## Stick-Breaking

La forma de trabajar directamente con un Proceso de Dirichlet vino dada por una construcción stick-breaking indefinida.

```{=tex}
\begin{theo}[(Sethuraman, 1994)]
  Sea $w_h = \upsilon \prod_{l<h} (1 - \upsilon_l)$ con $\upsilon_h \overset{i.i.d.}{\sim} \text{Beta}(1, \alpha)$ y $m_h \overset{i.i.d.}{\sim} G_0$, donde $(\upsilon_h)$ y $(m_h)$ son independientes entre sí. Luego,

  \begin{equation*}
    G(\cdot) = \sum_{h=1}^\infty w_h \delta_{m_h}(\cdot)
  \end{equation*}
  
  define un Proceso de Dirichlet de parámetros $\alpha$ y $G_0$.
\end{theo}
```

En la Figura 4 se pequeña una pequeña ilustración del proceso stick-breaking para obtener un Proceso de Dirichlet.

::: {#fig-stickbreaking}
![](figuras/DP%20-%20Stick%20Breaking.jpg)

Ilustación del proceso de Stick-Breaking
:::

Ahora, lo anterior sigue teniendo un pequeño problema, y es que claramente no podemos repetir el proceso una cantidad infinita de veces para obtener las secuencias infinitas de pesos y localizaciones. Para arreglar esto, se propone simplemente truncar la representación hasta un valor $H$ fijo, considerando $\upsilon_H = 1$, u obtener los pesos $w_h$ hasta cubrir un cierto número fijo, cercano a 1, de probabilidad.

```{=tex}
\begin{ejemplo}[Stick-Breaking]
\end{ejemplo}
```



```{julia}
#| label: fig-dp-normal
#| echo: false
#| fig-cap: Simulaciones Proceso de Dirichlet con medida de centralización Normal (en rojo)
#| fig-subcap:
#|   - M = 1
#|   - M = 10
#|   - M = 50
#|   - M = 100
#|   - M = 500
#|   - M = 1000
#| layout-ncol: 3
#| layout-nrow: 2

Random.seed!(219);
G0 = Distributions.Normal(0, 1)
display(tic_rdp_example(15, 1, G0, -10, 10, (-3, 3)))
display(tic_rdp_example(15, 10, G0, -10, 10, (-3, 3)))
display(tic_rdp_example(15, 50, G0, -10, 10, (-3, 3)))
display(tic_rdp_example(15, 100, G0, -10, 10, (-3, 3)))
display(tic_rdp_example(15, 500, G0, -10, 10, (-3, 3)))
display(tic_rdp_example(15, 1000, G0, -10, 10, (-3, 3)))
```

```{=tex}
\begin{nota}
  En este punto del trabajo fue donde decidí cambiarme de R a Julia, ya que las simulaciones anteriores tomaban demasiado tiempo. Utilizando Julia obtuve una mejoría en rapidez de casi 100 veces.
\end{nota}
```

## Algunos resultados asintóticos

Resultados de Antoniak, Korwar & Hollander.

```{julia}
#| echo: false

Random.seed!(219)
n_values = 1000:2000:21000

akh_empirical(n_values, 100)
```


\newpage
# Dirichlet Process Mixture Models

## Definición

## Simulación a posteriori

Gibbs:

* Caso conjugado:
  * Escobar (1988, 1994)
  * Escobar & West (1995)
  * Bush & MacEachern (1996)
* Caso no-conjugado:
  * No-gaps, MacEachern & Müller (1998)
  * Algoritmo 8, Neal (2000)

Otros: slice sampler, DP finito, inferencia variacional, etc. DP $\epsilon$-finito.


\newpage
# Particiones Aleatorias y Clustering

\newpage
# Aplicación: Modelo CAPM

aaaa

\newpage
# Referencias
---
nocite: |
  @*
---

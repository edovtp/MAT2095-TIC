
@book{severini_introduction_2018,
	title = {Introduction to {Statistical} {Methods} for {Financial} {Models}},
	isbn = {978-1-138-19837-1},
	abstract = {Title Page -- Copyright Page -- Dedication -- Table of Contents -- Preface -- 1 Introduction -- 2 Returns -- 2.1 Introduction -- 2.2 Basic Concepts -- 2.3 Adjusted Prices -- 2.4 Statistical Properties of Returns -- 2.5 Analyzing Return Data -- 2.6 Suggestions for Further Reading -- 2.7 Exercises -- 3 Random Walk Hypothesis -- 3.1 Introduction -- 3.2 Conditional Expectation -- 3.3 Efficient Markets and the Martingale Model -- 3.4 Random Walk Models for Asset Prices -- 3.5 Tests of the Random Walk Hypothesis -- 3.6 Do Stock Returns Follow the Random Walk Model? -- 3.7 Suggestions for Further Reading -- 3.8 Exercises -- 4 Portfolios -- 4.1 Introduction -- 4.2 Basic Concepts -- 4.3 Negative Portfolio Weights: Short Sales -- 4.4 Optimal Portfolios of Two Assets -- 4.5 Risk-Free Assets -- 4.6 Portfolios of Two Risky Assets and a Risk-Free Asset -- 4.7 Suggestions for Further Reading -- 4.8 Exercises -- 5 Efficient Portfolio Theory -- 5.1 Introduction -- 5.2 Portfolios of N Assets -- 5.3 Minimum-Risk Frontier -- 5.4 The Minimum-Variance Portfolio -- 5.5 The Efficient Frontier -- 5.6 Risk-Aversion Criterion -- 5.7 The Tangency Portfolio -- 5.8 Portfolio Constraints -- 5.9 Suggestions for Further Reading -- 5.10 Exercises -- 6 Estimation -- 6.1 Introduction -- 6.2 Basic Sample Statistics -- 6.3 Estimation of the Mean Vector and Covariance Matrix -- 6.4 Weighted Estimators -- 6.5 Shrinkage Estimators -- 6.6 Estimation of Portfolio Weights -- 6.7 Using Monte Carlo Simulation to Study the Properties of Estimators -- 6.8 Suggestions for Further Reading -- 6.9 Exercises -- 7 Capital Asset Pricing Model -- 7.1 Introduction -- 7.2 Security Market Line -- 7.3 Implications of the CAPM -- 7.4 Applying the CAPM to a Portfolio -- 7.5 Mispriced Assets -- 7.6 The CAPM without a Risk-Free Asset -- 7.7 Using the CAPM to Describe the Expected Returns on a Set of Assets},
	language = {en},
	publisher = {CRC Press, Taylor \& Francis Group},
	author = {Severini, Thomas A.},
	year = {2018},
	note = {Google-Books-ID: GR08nQAACAAJ},
	keywords = {Business \& Economics / Finance / General, Mathematics / Probability \& Statistics / General},
}

@article{korwar_contributions_1973,
	title = {Contributions to the {Theory} of {Dirichlet} {Processes}},
	volume = {1},
	issn = {0091-1798, 2168-894X},
	url = {https://projecteuclid.org/journals/annals-of-probability/volume-1/issue-4/Contributions-to-the-Theory-of-Dirichlet-Processes/10.1214/aop/1176996898.full},
	doi = {10.1214/aop/1176996898},
	abstract = {Consider a sample \$X\_1, {\textbackslash}cdots, X\_n\$ from a Dirichlet process \$P\$ on an uncountable standard Borel space \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$ where the parameter \${\textbackslash}alpha\$ of the process is assumed to be non-atomic and \${\textbackslash}sigma\$-additive. Let \$D(n)\$ be the number of distinct observations in the sample and denote these distinct observations by \$Y\_1, {\textbackslash}cdots, Y\_\{D(n)\}\$. Our main results are (1) \$D(n)/{\textbackslash}log n {\textbackslash}rightarrow\_\{{\textbackslash}operatorname\{a.s.\}\} {\textbackslash}alpha({\textbackslash}mathscr\{X\}), n {\textbackslash}rightarrow {\textbackslash}infty\$, and (2) given \$D(n), Y\_1, {\textbackslash}cdots, Y\_\{D(n)\}\$ are independent and identically distributed according to \${\textbackslash}alpha({\textbackslash}bullet)/{\textbackslash}alpha({\textbackslash}mathscr\{X\})\$. Result (1) shows that \${\textbackslash}alpha({\textbackslash}mathscr\{X\})\$ can be consistently estimated from the sample, and result (2) leads to a strong law for \${\textbackslash}sum{\textasciicircum}\{D(n)\}\_\{i=1\} Y\_i/D(n)\$.},
	number = {4},
	urldate = {2022-11-21},
	journal = {The Annals of Probability},
	author = {Korwar, Ramesh M. and Hollander, Myles},
	month = aug,
	year = {1973},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60K99, 62G05, consistent estimation, Dirichlet process, distribution theory, Strong law of large numbers},
	pages = {705--711},
	file = {Full Text PDF:/home/edovt/Zotero/storage/UDFRLJD5/Korwar and Hollander - 1973 - Contributions to the Theory of Dirichlet Processes.pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/XJSM8UKJ/1176996898.html:text/html},
}

@article{antoniak_mixtures_1974,
	title = {Mixtures of {Dirichlet} {Processes} with {Applications} to {Bayesian} {Nonparametric} {Problems}},
	volume = {2},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-2/issue-6/Mixtures-of-Dirichlet-Processes-with-Applications-to-Bayesian-Nonparametric-Problems/10.1214/aos/1176342871.full},
	doi = {10.1214/aos/1176342871},
	abstract = {A random process called the Dirichlet process whose sample functions are almost surely probability measures has been proposed by Ferguson as an approach to analyzing nonparametric problems from a Bayesian viewpoint. An important result obtained by Ferguson in this approach is that if observations are made on a random variable whose distribution is a random sample function of a Dirichlet process, then the conditional distribution of the random measure can be easily calculated, and is again a Dirichlet process. This paper extends Ferguson's result to cases where the random measure is a mixing distribution for a parameter which determines the distribution from which observations are made. The conditional distribution of the random measure, given the observations, is no longer that of a simple Dirichlet process, but can be described as being a mixture of Dirichlet processes. This paper gives a formal definition for these mixtures and develops several theorems about their properties, the most important of which is a closure property for such mixtures. Formulas for computing the conditional distribution are derived and applications to problems in bio-assay, discrimination, regression, and mixing distributions are given.},
	number = {6},
	urldate = {2022-11-21},
	journal = {The Annals of Statistics},
	author = {Antoniak, Charles E.},
	month = nov,
	year = {1974},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {60K99, Dirichlet process, 60G35, 62C10, 62G99, Bayes, bio-assay, discrimination, Empirical Bayes, mixing distribution, nonparametric, Random measures},
	pages = {1152--1174},
	file = {Full Text PDF:/home/edovt/Zotero/storage/Q454CTCD/Antoniak - 1974 - Mixtures of Dirichlet Processes with Applications .pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/EIA23G5F/1176342871.html:text/html},
}

@article{geman_stochastic_1984,
	title = {Stochastic {Relaxation}, {Gibbs} {Distributions}, and the {Bayesian} {Restoration} of {Images}},
	volume = {PAMI-6},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.1984.4767596},
	abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (“annealing”), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel “relaxation” algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Geman, Stuart and Geman, Donald},
	month = nov,
	year = {1984},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Additive noise, Annealing, Bayesian methods, Deformable models, Degradation, Energy states, Gibbs distribution, image restoration, Image restoration, line process, MAP estimate, Markov random field, Markov random fields, relaxation, scene modeling, spatial degradation, Stochastic processes, Temperature distribution},
	pages = {721--741},
	file = {IEEE Xplore Abstract Record:/home/edovt/Zotero/storage/MIQQDGQV/4767596.html:text/html},
}

@article{jara_dppackage_2011,
	title = {{DPpackage}: {Bayesian} {Semi}- and {Nonparametric} {Modeling} in {R}},
	volume = {40},
	copyright = {Copyright (c) 2009 Alejandro Jara, Timothy Hanson, Fernando A. Quintana, Peter Müller, Gary L. Rosner},
	issn = {1548-7660},
	shorttitle = {{DPpackage}},
	url = {https://doi.org/10.18637/jss.v040.i05},
	doi = {10.18637/jss.v040.i05},
	abstract = {Data analysis sometimes requires the relaxation of parametric assumptions in order to gain modeling flexibility and robustness against mis-specification of the probability model. In the Bayesian context, this is accomplished by placing a prior distribution on a function space, such as the space of all probability distributions or the space of all regression functions. Unfortunately, posterior distributions ranging over function spaces are highly complex and hence sampling methods play a key role. This paper provides an introduction to a simple, yet comprehensive, set of programs for the implementation of some Bayesian nonparametric and semiparametric models in R, DPpackage. Currently, DPpackage includes models for marginal and conditional density estimation, receiver operating characteristic curve analysis, interval-censored data, binary regression data, item response data, longitudinal and clustered data using generalized linear mixed models, and regression data using generalized additive models. The package also contains functions to compute pseudo-Bayes factors for model comparison and for eliciting the precision parameter of the Dirichlet process prior, and a general purpose Metropolis sampling algorithm. To maximize computational efficiency, the actual sampling for each model is carried out using compiled C, C++ or Fortran code.},
	language = {en},
	urldate = {2022-11-17},
	journal = {Journal of Statistical Software},
	author = {Jara, Alejandro and Hanson, Timothy and Quintana, Fernando A. and Müller, Peter and Rosner, Gary L.},
	month = apr,
	year = {2011},
	pages = {1--30},
}

@misc{ross_dirichletprocess_2020,
	title = {dirichletprocess: {Build} {Dirichlet} {Process} {Objects} for {Bayesian} {Modelling}},
	copyright = {GPL-3},
	shorttitle = {dirichletprocess},
	url = {https://CRAN.R-project.org/package=dirichletprocess},
	abstract = {Perform nonparametric Bayesian analysis using Dirichlet processes without the need to program the inference algorithms. Utilise included pre-built models or specify custom models and allow the 'dirichletprocess' package to handle the Markov chain Monte Carlo sampling. Our Dirichlet process objects can act as building blocks for a variety of statistical models including and not limited to: density estimation, clustering and prior distributions in hierarchical models. See Teh, Y. W. (2011) {\textless}https://www.stats.ox.ac.uk/{\textasciitilde}teh/research/npbayes/Teh2010a.pdf{\textgreater}, among many other sources.},
	urldate = {2022-11-17},
	author = {Ross, Gordon J. and Markwick, Dean and Mulder, Kees and Sighinolfi, Giovanni},
	month = jun,
	year = {2020},
	keywords = {Bayesian},
}

@article{sethuraman_constructive_1994,
	title = {A {Constructive} {Definition} of {Dirichlet} {Priors}},
	volume = {4},
	issn = {1017-0405},
	url = {https://www.jstor.org/stable/24305538},
	abstract = {In this paper we give a simple and new constructive definition of Dirichlet measures removing the restriction that the basic space should be Rk. We also give complete, self contained proofs of the three basic results for Dirichlet measures: 1. The Dirichlet measure is a probability measure on the space of all probability measures. 2. It gives probability one to the subset of discrete probability measures. 3. The posterior distribution is also a Dirichlet measure.},
	number = {2},
	urldate = {2022-11-12},
	journal = {Statistica Sinica},
	author = {Sethuraman, Jayaram},
	year = {1994},
	note = {Publisher: Institute of Statistical Science, Academia Sinica},
	pages = {639--650},
}

@article{ferguson_bayesian_1973,
	title = {A {Bayesian} {Analysis} of {Some} {Nonparametric} {Problems}},
	volume = {1},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-1/issue-2/A-Bayesian-Analysis-of-Some-Nonparametric-Problems/10.1214/aos/1176342360.full},
	doi = {10.1214/aos/1176342360},
	abstract = {The Bayesian approach to statistical problems, though fruitful in many ways, has been rather unsuccessful in treating nonparametric problems. This is due primarily to the difficulty in finding workable prior distributions on the parameter space, which in nonparametric ploblems is taken to be a set of probability distributions on a given sample space. There are two desirable properties of a prior distribution for nonparametric problems. (I) The support of the prior distribution should be large--with respect to some suitable topology on the space of probability distributions on the sample space. (II) Posterior distributions given a sample of observations from the true probability distribution should be manageable analytically. These properties are antagonistic in the sense that one may be obtained at the expense of the other. This paper presents a class of prior distributions, called Dirichlet process priors, broad in the sense of (I), for which (II) is realized, and for which treatment of many nonparametric statistical problems may be carried out, yielding results that are comparable to the classical theory. In Section 2, we review the properties of the Dirichlet distribution needed for the description of the Dirichlet process given in Section 3. Briefly, this process may be described as follows. Let \${\textbackslash}mathscr\{X\}\$ be a space and \${\textbackslash}mathscr\{A\}\$ a \${\textbackslash}sigma\$-field of subsets, and let \${\textbackslash}alpha\$ be a finite non-null measure on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$. Then a stochastic process \$P\$ indexed by elements \$A\$ of \${\textbackslash}mathscr\{A\}\$, is said to be a Dirichlet process on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$ with parameter \${\textbackslash}alpha\$ if for any measurable partition \$(A\_1, {\textbackslash}cdots, A\_k)\$ of \${\textbackslash}mathscr\{X\}\$, the random vector \$(P(A\_1), {\textbackslash}cdots, P(A\_k))\$ has a Dirichlet distribution with parameter \$({\textbackslash}alpha(A\_1), {\textbackslash}cdots, {\textbackslash}alpha(A\_k)). P\$ may be considered a random probability measure on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$, The main theorem states that if \$P\$ is a Dirichlet process on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$ with parameter \${\textbackslash}alpha\$, and if \$X\_1, {\textbackslash}cdots, X\_n\$ is a sample from \$P\$, then the posterior distribution of \$P\$ given \$X\_1, {\textbackslash}cdots, X\_n\$ is also a Dirichlet process on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$ with a parameter \${\textbackslash}alpha + {\textbackslash}sum{\textasciicircum}n\_1 {\textbackslash}delta\_\{x\_i\}\$, where \${\textbackslash}delta\_x\$ denotes the measure giving mass one to the point \$x\$. In Section 4, an alternative definition of the Dirichlet process is given. This definition exhibits a version of the Dirichlet process that gives probability one to the set of discrete probability measures on \$({\textbackslash}mathscr\{X\}, {\textbackslash}mathscr\{A\})\$. This is in contrast to Dubins and Freedman [2], whose methods for choosing a distribution function on the interval [0, 1] lead with probability one to singular continuous distributions. Methods of choosing a distribution function on [0, 1] that with probability one is absolutely continuous have been described by Kraft [7]. The general method of choosing a distribution function on [0, 1], described in Section 2 of Kraft and van Eeden [10], can of course be used to define the Dirichlet process on [0, 1]. Special mention must be made of the papers of Freedman and Fabius. Freedman [5] defines a notion of tailfree for a distribution on the set of all probability measures on a countable space \${\textbackslash}mathscr\{X\}\$. For a tailfree prior, posterior distribution given a sample from the true probability measure may be fairly easily computed. Fabius [3] extends the notion of tailfree to the case where \${\textbackslash}mathscr\{X\}\$ is the unit interval [0, 1], but it is clear his extension may be made to cover quite general \${\textbackslash}mathscr\{X\}\$. With such an extension, the Dirichlet process would be a special case of a tailfree distribution for which the posterior distribution has a particularly simple form. There are disadvantages to the fact that \$P\$ chosen by a Dirichlet process is discrete with probability one. These appear mainly because in sampling from a \$P\$ chosen by a Dirichlet process, we expect eventually to see one observation exactly equal to another. For example, consider the goodness-of-fit problem of testing the hypothesis \$H\_0\$ that a distribution on the interval [0, 1] is uniform. If on the alternative hypothesis we place a Dirichlet process prior with parameter \${\textbackslash}alpha\$ itself a uniform measure on [0, 1], and if we are given a sample of size \$n {\textbackslash}geqq 2\$, the only nontrivial nonrandomized Bayes rule is to reject \$H\_0\$ if and only if two or more of the observations are exactly equal. This is really a test of the hypothesis that a distribution is continuous against the hypothesis that it is discrete. Thus, there is still a need for a prior that chooses a continuous distribution with probability one and yet satisfies properties (I) and (II). Some applications in which the possible doubling up of the values of the observations plays no essential role are presented in Section 5. These include the estimation of a distribution function, of a mean, of quantiles, of a variance and of a covariance. A two-sample problem is considered in which the Mann-Whitney statistic, equivalent to the rank-sum statistic, appears naturally. A decision theoretic upper tolerance limit for a quantile is also treated. Finally, a hypothesis testing problem concerning a quantile is shown to yield the sign test. In each of these problems, useful ways of combining prior information with the statistical observations appear. Other applications exist. In his Ph. D. dissertation [1], Charles Antoniak finds a need to consider mixtures of Dirichlet processes. He treats several problems, including the estimation of a mixing distribution, bio-assay, empirical Bayes problems, and discrimination problems.},
	number = {2},
	urldate = {2022-11-12},
	journal = {The Annals of Statistics},
	author = {Ferguson, Thomas S.},
	month = mar,
	year = {1973},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {209--230},
	file = {Full Text PDF:/home/edovt/Zotero/storage/RPNXFQSB/Ferguson - 1973 - A Bayesian Analysis of Some Nonparametric Problems.pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/V26TKSCL/1176342360.html:text/html},
}

@article{blackwell_ferguson_1973,
	title = {Ferguson {Distributions} {Via} {Polya} {Urn} {Schemes}},
	volume = {1},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-1/issue-2/Ferguson-Distributions-Via-Polya-Urn-Schemes/10.1214/aos/1176342372.full},
	doi = {10.1214/aos/1176342372},
	abstract = {The Polya urn scheme is extended by allowing a continuum of colors. For the extended scheme, the distribution of colors after \$n\$ draws is shown to converge as \$n {\textbackslash}rightarrow {\textbackslash}infty\$ to a limiting discrete distribution \${\textbackslash}mu{\textasciicircum}{\textbackslash}ast\$. The distribution of \${\textbackslash}mu{\textasciicircum}{\textbackslash}ast\$ is shown to be one introduced by Ferguson and, given \${\textbackslash}mu{\textasciicircum}{\textbackslash}ast\$, the colors drawn from the urn are shown to be independent with distribution \${\textbackslash}mu{\textasciicircum}{\textbackslash}ast\$.},
	number = {2},
	urldate = {2022-11-10},
	journal = {The Annals of Statistics},
	author = {Blackwell, David and MacQueen, James B.},
	month = mar,
	year = {1973},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {353--355},
	file = {Full Text PDF:/home/edovt/Zotero/storage/LKEIBB5X/Blackwell and MacQueen - 1973 - Ferguson Distributions Via Polya Urn Schemes.pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/TB7WKW6C/1176342372.html:text/html},
}

@article{ohagan_dicing_2004,
	title = {Dicing with the unknown},
	volume = {1},
	issn = {1740-9713},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2004.00050.x},
	doi = {10.1111/j.1740-9713.2004.00050.x},
	abstract = {There are many things that I am uncertain about, says Tony O'Hagan. Some are merely unknown to me, while others are unknowable. This article is about different kinds of uncertainty, and how the distinction between them impinges on the foundations of Probability and Statistics.},
	language = {en},
	number = {3},
	urldate = {2022-11-09},
	journal = {Significance},
	author = {O'Hagan, Tony},
	year = {2004},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2004.00050.x},
	pages = {132--133},
	file = {Full Text PDF:/home/edovt/Zotero/storage/F4ZHS9MV/O'Hagan - 2004 - Dicing with the unknown.pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/ZLCZZIG7/j.1740-9713.2004.00050.html:text/html},
}

@book{gelman_bayesian_2014,
	address = {Boca Raton},
	edition = {Third edition},
	series = {Chapman \& {Hall}/{CRC} texts in statistical science},
	title = {Bayesian data analysis},
	isbn = {978-1-4398-4095-5},
	abstract = {"Preface This book is intended to have three roles and to serve three associated audiences: an introductory text on Bayesian inference starting from first principles, a graduate text on effective current approaches to Bayesian modeling and computation in statistics and related fields, and a handbook of Bayesian methods in applied statistics for general users of and researchers in applied statistics. Although introductory in its early sections, the book is definitely not elementary in the sense of a first text in statistics. The mathematics used in our book is basic probability and statistics, elementary calculus, and linear algebra. A review of probability notation is given in Chapter 1 along with a more detailed list of topics assumed to have been studied. The practical orientation of the book means that the reader's previous experience in probability, statistics, and linear algebra should ideally have included strong computational components. To write an introductory text alone would leave many readers with only a taste of the conceptual elements but no guidance for venturing into genuine practical applications, beyond those where Bayesian methods agree essentially with standard non-Bayesian analyses. On the other hand, we feel it would be a mistake to present the advanced methods without first introducing the basic concepts from our data-analytic perspective. Furthermore, due to the nature of applied statistics, a text on current Bayesian methodology would be incomplete without a variety of worked examples drawn from real applications. To avoid cluttering the main narrative, there are bibliographic notes at the end of each chapter and references at the end of the book"--},
	publisher = {CRC Press},
	author = {Gelman, Andrew},
	year = {2014},
	keywords = {Bayesian statistical decision theory, MATHEMATICS / Probability \& Statistics / General},
}

@book{muller_bayesian_2015,
	address = {Cham},
	series = {Springer {Series} in {Statistics}},
	title = {Bayesian {Nonparametric} {Data} {Analysis}},
	isbn = {978-3-319-18967-3 978-3-319-18968-0},
	url = {http://link.springer.com/10.1007/978-3-319-18968-0},
	urldate = {2022-07-23},
	publisher = {Springer International Publishing},
	author = {Müller, Peter and Quintana, Fernando Andres and Jara, Alejandro and Hanson, Tim},
	year = {2015},
	doi = {10.1007/978-3-319-18968-0},
	file = {(Springer Series in Statistics) Peter Müller, Fernando Andres Quintana, Alejandro Jara, Tim Hanson (auth.) - Bayesian Nonparametric Data Analysis-Springer International Publishing (2015).pdf:/mnt/Datos/Estadística UC/MAT2095 - Taller de Iniciación Científica/Libros/(Springer Series in Statistics) Peter Müller, Fernando Andres Quintana, Alejandro Jara, Tim Hanson (auth.) - Bayesian Nonparametric Data Analysis-Springer International Publishing (2015).pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/SDAAUN5V/978-3-319-18968-0.html:text/html},
}

@article{ni_scalable_2020,
	title = {Scalable {Bayesian} {Nonparametric} {Clustering} and {Classification}},
	volume = {29},
	issn = {1061-8600},
	url = {https://doi.org/10.1080/10618600.2019.1624366},
	doi = {10.1080/10618600.2019.1624366},
	abstract = {We develop a scalable multistep Monte Carlo algorithm for inference under a large class of nonparametric Bayesian models for clustering and classification. Each step is “embarrassingly parallel” and can be implemented using the same Markov chain Monte Carlo sampler. The simplicity and generality of our approach make inference for a wide range of Bayesian nonparametric mixture models applicable to large datasets. Specifically, we apply the approach to inference under a product partition model with regression on covariates. We show results for inference with two motivating datasets: a large set of electronic health records and a bank telemarketing dataset. We find interesting clusters and competitive classification performance relative to other widely used competing classifiers. Supplementary materials for this article are available online.},
	number = {1},
	urldate = {2022-07-19},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Ni, Yang and Müller, Peter and Diesendruck, Maurice and Williamson, Sinead and Zhu, Yitan and Ji, Yuan},
	month = jan,
	year = {2020},
	pmid = {32982129},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10618600.2019.1624366},
	keywords = {Electronic health records, Nonconjugate models, Parallel computing, Product partition models},
	pages = {53--65},
	file = {Accepted Version:/home/edovt/Zotero/storage/2PS5XEB7/Ni et al. - 2020 - Scalable Bayesian Nonparametric Clustering and Cla.pdf:application/pdf;Snapshot:/home/edovt/Zotero/storage/W3G2IEHL/10618600.2019.html:text/html},
}

@article{neal_markov_2000,
	title = {Markov {Chain} {Sampling} {Methods} for {Dirichlet} {Process} {Mixture} {Models}},
	volume = {9},
	issn = {1061-8600},
	url = {https://www.jstor.org/stable/1390653},
	doi = {10.2307/1390653},
	abstract = {This article reviews Markov chain methods for sampling from the posterior distribution of a Dirichlet process mixture model and presents two new classes of methods. One new approach is to make Metropolis-Hastings updates of the indicators specifying which mixture component is associated with each observation, perhaps supplemented with a partial form of Gibbs sampling. The other new approach extends Gibbs sampling for these indicators by using a set of auxiliary parameters. These methods are simple to implement and are more efficient than previous ways of handling general Dirichlet process mixture models with non-conjugate priors.},
	number = {2},
	urldate = {2022-07-19},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Neal, Radford M.},
	year = {2000},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
	pages = {249--265},
	file = {Neal, M. - Markov Chain Sampling Methods for Dirichlet Process Mixture Models.pdf:/mnt/Datos/Estadística UC/MAT2095 - Taller de Iniciación Científica/Artículos/Neal, M. - Markov Chain Sampling Methods for Dirichlet Process Mixture Models.pdf:application/pdf},
}

@article{escobar_bayesian_1995,
	title = {Bayesian {Density} {Estimation} and {Inference} {Using} {Mixtures}},
	volume = {90},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2291069},
	doi = {10.2307/2291069},
	abstract = {We describe and illustrate Bayesian inference in models for density estimation using mixtures of Dirichlet processes. These models provide natural settings for density estimation and are exemplified by special cases where data are modeled as a sample from mixtures of normal distributions. Efficient simulation methods are used to approximate various prior, posterior, and predictive distributions. This allows for direct inference on a variety of practical issues, including problems of local versus global smoothing, uncertainty about density estimates, assessment of modality, and the inference on the numbers of components. Also, convergence results are established for a general class of normal mixture models.},
	number = {430},
	urldate = {2022-07-19},
	journal = {Journal of the American Statistical Association},
	author = {Escobar, Michael D. and West, Mike},
	year = {1995},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {577--588},
	file = {Escobar, M. & West, M. - Bayesian Density Estimation and Inference Using Mixtures.pdf:/mnt/Datos/Estadística UC/MAT2095 - Taller de Iniciación Científica/Artículos/Escobar, M. & West, M. - Bayesian Density Estimation and Inference Using Mixtures.pdf:application/pdf},
}

@article{dahl_search_2022,
	title = {Search {Algorithms} and {Loss} {Functions} for {Bayesian} {Clustering}},
	volume = {31},
	issn = {1061-8600, 1537-2715},
	url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2022.2069779},
	doi = {10.1080/10618600.2022.2069779},
	language = {en},
	number = {4},
	urldate = {2022-12-27},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Dahl, David B. and Johnson, Devin J. and Müller, Peter},
	month = oct,
	year = {2022},
	pages = {1189--1201},
	file = {Submitted Version:/home/edovt/Zotero/storage/MWLEIPK7/Dahl et al. - 2022 - Search Algorithms and Loss Functions for Bayesian .pdf:application/pdf},
}

@misc{page_ppmsuite_2022,
	title = {{ppmSuite}: {A} {Collection} of {Models} that {Employ} a {Product} {Partition} {Distribution} as a {Prior} on {Partitions}},
	copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL]},
	shorttitle = {{ppmSuite}},
	url = {https://CRAN.R-project.org/package=ppmSuite},
	abstract = {Provides a suite of functions that fit models that use PPM type priors for partitions. Models include hierarchical Gaussian and probit ordinal models with a (covariate dependent) PPM. If a covariate dependent product partition model is selected, then all the options detailed in Page, G.L.; Quintana, F.A. (2018) {\textless}doi:10.1007/s11222-017-9777-z{\textgreater} are available. If covariate values are missing, then the approach detailed in Page, G.L.; Quintana, F.A.; Mueller, P (2020) {\textless}doi:10.1080/10618600.2021.1999824{\textgreater} is employed. Also included in the package is a function that fits a Gaussian likelihood spatial product partition model that is detailed in Page, G.L.; Quintana, F.A. (2016) {\textless}doi:10.1214/15-BA971{\textgreater}, and multivariate PPM change point models that are detailed in Quinlan, J.J.; Page, G.L.; Castro, L.M. (2021) {\textless}arXiv:2201.07830{\textgreater}.},
	urldate = {2022-12-27},
	author = {Page, Garritt L. and Quinlan, Jose J. and Curtis, S. McKay and Neal, Radford M.},
	month = jun,
	year = {2022},
	keywords = {MissingData},
}

@article{bezanson_julia_2017,
	title = {Julia: {A} {Fresh} {Approach} to {Numerical} {Computing}},
	volume = {59},
	issn = {0036-1445, 1095-7200},
	shorttitle = {Julia},
	url = {https://epubs.siam.org/doi/10.1137/141000671},
	doi = {10.1137/141000671},
	language = {en},
	number = {1},
	urldate = {2022-12-27},
	journal = {SIAM Review},
	author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B.},
	month = jan,
	year = {2017},
	pages = {65--98},
	file = {Full Text:/home/edovt/Zotero/storage/WL63P7VR/Bezanson et al. - 2017 - Julia A Fresh Approach to Numerical Computing.pdf:application/pdf},
}

@article{muliere_approximating_1998,
	title = {Approximating distributions of random functionals of {Ferguson}-{Dirichlet} priors},
	volume = {26},
	issn = {03195724, 1708945X},
	url = {http://doi.wiley.com/10.2307/3315511},
	doi = {10.2307/3315511},
	language = {en},
	number = {2},
	urldate = {2023-01-21},
	journal = {Canadian Journal of Statistics},
	author = {Muliere, Pietro and Tardella, Luca},
	month = jun,
	year = {1998},
	pages = {283--297},
}

@article{ishwaran_markov_2000,
	title = {Markov chain {Monte} {Carlo} in approximate {Dirichlet} and beta two-parameter process hierarchical models},
	volume = {87},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/87.2.371},
	doi = {10.1093/biomet/87.2.371},
	language = {en},
	number = {2},
	urldate = {2023-01-21},
	journal = {Biometrika},
	author = {Ishwaran, H and Zarepour, M},
	month = jun,
	year = {2000},
	pages = {371--390},
}
